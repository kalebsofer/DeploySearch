{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.preprocess_str import preprocess_query\n",
    "from utils.load_data import load_word2vec\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I want to book a flight from New York to London\"\n",
    "# processed_query = preprocess_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, embeddings, word_to_idx = load_word2vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_string_embedding(input_string, vocab, word_to_idx, embeddings):\n",
    "    # Preprocess the string the same way as during training\n",
    "    processed_words = preprocess_query(input_string)\n",
    "\n",
    "    # Initialize a list to store embeddings of each word\n",
    "    word_embeddings = []\n",
    "\n",
    "    # Get embedding for each word if it exists in vocabulary\n",
    "    for word in processed_words:\n",
    "        if word in word_to_idx:\n",
    "            # Get the index of the word\n",
    "            word_idx = word_to_idx[word]\n",
    "            # Get the embedding for this word\n",
    "            word_embedding = embeddings[word_idx]\n",
    "            word_embeddings.append(word_embedding)\n",
    "\n",
    "    if not word_embeddings:\n",
    "        # Return zeros if no words were found in vocabulary\n",
    "        return torch.zeros(embeddings.shape[1])\n",
    "\n",
    "    # Stack all word embeddings and take mean\n",
    "    # This gives us a single vector representing the entire string\n",
    "    string_embedding = torch.stack(word_embeddings).mean(dim=0)\n",
    "\n",
    "    return string_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1078,  0.2759,  0.8006, -0.8133, -0.1181,  0.1671, -0.1864, -0.7303,\n",
       "         0.5745, -0.7744, -0.0660, -0.4620, -1.4618, -0.3244,  0.3230, -0.5889,\n",
       "         1.2036,  0.3766,  0.6111, -1.4937, -0.0879,  0.4346,  0.2056, -0.2553,\n",
       "        -0.2370, -0.0523, -0.5759,  0.0228,  0.1941,  0.6478, -0.2697,  0.7104,\n",
       "        -0.4996, -0.1627, -0.3474, -0.4425,  0.1650, -0.2164,  0.2090, -0.3872,\n",
       "         0.3040, -0.4904,  0.0562,  0.3476,  0.5981,  0.8066,  0.9653, -0.6778,\n",
       "        -0.5259, -0.5653,  0.8935, -0.1580,  0.5630,  0.3995, -0.9374, -0.1637,\n",
       "         0.7997,  0.0065,  0.1903,  1.1658, -0.4727, -1.4879, -0.3455, -0.0875,\n",
       "        -0.1593, -0.0892, -0.1010, -0.6143,  1.2531, -0.1606, -0.0346, -0.4433,\n",
       "        -0.7188, -0.1590,  0.4837, -1.5664,  0.3333, -0.4420,  0.8076, -0.4140,\n",
       "        -0.3467,  0.5054,  1.0810, -1.1074,  0.5150,  0.0513,  0.7043,  0.4091,\n",
       "         0.3042, -0.5030,  0.5532,  0.9024,  0.4304, -0.2394,  0.0216,  0.6446,\n",
       "        -0.3835, -0.1401,  0.1156, -0.1687])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "embedding = get_string_embedding(query, vocab, word_to_idx, embeddings)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
